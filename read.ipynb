{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "''\n",
      "Attempting to process file: ./database/pc_EC2_4_000010.db\n",
      "Connected to ./database/pc_EC2_4_000010.db database.\n",
      "CLFiltration:assuming ordinal number filtration values.\n",
      "CLFiltration:assuming ordinal number filtration values.\n",
      "Attempt 1/100: No matching sample found. Retrying...\n",
      "Attempting to process file: ./database/pc_EC2_4_000010.db\n",
      "Connected to ./database/pc_EC2_4_000010.db database.\n",
      "CLFiltration:assuming ordinal number filtration values.\n",
      "CLFiltration:assuming ordinal number filtration values.\n",
      "Attempt 2/100: No matching sample found. Retrying...\n",
      "Attempting to process file: ./database/pc_EC2_4_000010.db\n",
      "Connected to ./database/pc_EC2_4_000010.db database.\n",
      "CLFiltration:assuming ordinal number filtration values.\n",
      "CLFiltration:assuming ordinal number filtration values.\n",
      "Attempting to process file: ./database/pc_EC2_n_000001.db\n",
      "Connected to ./database/pc_EC2_n_000001.db database.\n",
      "CLFiltration:assuming ordinal number filtration values.\n",
      "CLFiltration:assuming ordinal number filtration values.\n",
      "Attempt 1/100: No matching sample found. Retrying...\n",
      "Attempting to process file: ./database/pc_EC2_n_000001.db\n",
      "Connected to ./database/pc_EC2_n_000001.db database.\n",
      "CLFiltration:assuming ordinal number filtration values.\n",
      "CLFiltration:assuming ordinal number filtration values.\n",
      "Attempt 2/100: No matching sample found. Retrying...\n",
      "Attempting to process file: ./database/pc_EC2_n_000001.db\n",
      "Connected to ./database/pc_EC2_n_000001.db database.\n",
      "CLFiltration:assuming ordinal number filtration values.\n",
      "CLFiltration:assuming ordinal number filtration values.\n",
      "Attempt 3/100: No matching sample found. Retrying...\n",
      "Attempting to process file: ./database/pc_EC2_n_000001.db\n",
      "Connected to ./database/pc_EC2_n_000001.db database.\n",
      "CLFiltration:assuming ordinal number filtration values.\n",
      "CLFiltration:assuming ordinal number filtration values.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from commutazzio.filtration import CLFiltration\n",
    "from commutazzio.compute import CLInvariants\n",
    "from commutazzio.filtration import CLFiltrationDB\n",
    "# from commutazzio.plot import ComplementaryTrianglesPlot as Visualizer1\n",
    "import random\n",
    "import numpy as np\n",
    "# from echoflare import send_finish_message\n",
    "from commutazzio.utils import filepath_generator\n",
    "import csv\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = None\n",
    "pd.set_option('display.max_columns', None)\n",
    "from read_database import sqlite_to_df_cl4_pc, sqlite_to_df_cln_pc\n",
    "import os\n",
    "import glob \n",
    "import random\n",
    "import os\n",
    "\n",
    "def get_one_sample(dirname, fn_pattern, required_space_dim=[2], max_attempts=100):\n",
    "    attempts = 0\n",
    "    # Loop through all files in the directory matching the pattern\n",
    "    while attempts < max_attempts:\n",
    "        for filename in glob.glob(os.path.join(dirname, f\"{fn_pattern}*.db\")):\n",
    "            print(f\"Attempting to process file: {filename}\")\n",
    "            new_db = CLFiltrationDB(filename, create_new_db=False, table_name='clf_filtration')\n",
    "            \n",
    "            # Randomize the id to be an integer between 1 and 100\n",
    "            sample = new_db.get_filtration_by_id(random.randint(1, 100))\n",
    "\n",
    "            # Check if the sample has the required space dimension\n",
    "            if sample is not None and hasattr(sample, 'info') and sample.info['space_dim'] in required_space_dim:\n",
    "                return sample\n",
    "\n",
    "        attempts += 1\n",
    "        print(f\"Attempt {attempts}/{max_attempts}: No matching sample found. Retrying...\")\n",
    "\n",
    "    # If no files found or no matching sample found after max_attempts, return None\n",
    "    print(\"No matching sample found.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "# dirname_topoblaze = './database/TopoBlaze'\n",
    "# dirname_nebulacompute = './database/NebulaCompute'\n",
    "# dirname_mac= './database'\n",
    "dirname= './database'\n",
    "fn_pattern_cl4 = 'pc_EC2_4'\n",
    "fn_pattern_cln = 'pc_EC2_n'\n",
    "sample_cl4 = get_one_sample(dirname, fn_pattern_cl4)\n",
    "sample_cln = get_one_sample(dirname, fn_pattern_cln)\n",
    "# Now, 'sample' contains the data from the first matching file, or None if no files were found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_cl4.info['space_dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a simplex tree with 2488 simplices and 4 filtration values @ 0x30c3b7380"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_cl4.upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLFiltration:assuming ordinal number filtration values.\n",
      "Filtration updated.\n",
      "Number of cores being used: 12\n",
      "Computing multiplicity vector @ dim=0 with prime=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  49%|████▊     | 37/76 [00:01<00:01, 35.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n",
      "''\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 76/76 [00:01<00:00, 48.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiplicity vector computed (dim=0, prime=2).\n",
      "Total decomposition of the homology module at dimension 0 and finite field F2 is computed.\n",
      "Number of cores being used: 12\n",
      "Computing multiplicity vector @ dim=1 with prime=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 76/76 [00:00<00:00, 356.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiplicity vector computed (dim=1, prime=2).\n",
      "Total decomposition of the homology module at dimension 1 and finite field F2 is computed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'I21': 2, 'I41': 1, 'I51': 1, 'I55': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a CL(4) filtration object from two A4 filtrations of simplicial complexes\n",
    "from commutazzio.filtration import CLFiltration\n",
    "clf=CLFiltration(upper=sample_cl4.upper, lower=sample_cl4.lower)\n",
    "# compute its decomposition\n",
    "from commutazzio.compute import CLInvariants\n",
    "inv=CLInvariants(clf,enable_multi_processing=True)\n",
    "inv.total_decomposition_computation(dim=0)\n",
    "inv.total_decomposition_computation(dim=1)\n",
    "inv.decompositions_all[0].nonzero_components\n",
    "inv.decompositions_all[1].nonzero_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromatic_tda as chro\n",
    "\n",
    "def configure_chromatic_simplicial_complex(clf):\n",
    "    # Step 1: Extract simplices and their filtration values from clf.upper\n",
    "    upper_simplices = {tuple(s): fv for s,fv in clf.upper}\n",
    "\n",
    "    # Step 2: Adjust the filtration values to start from 0 and be integers\n",
    "    min_filtration = min(upper_simplices.values())\n",
    "    adjusted_simplices = {simplex: int(value - min_filtration) for simplex, value in upper_simplices.items()}\n",
    "\n",
    "    # Step 3: Define a dictionary mapping each simplex to its adjusted filtration value\n",
    "    complex_simplices = {simplex: adjusted_simplices.get(simplex, 0) for simplex in adjusted_simplices}\n",
    "    # Step 4: Extract the maximum simplices from clf.lower\n",
    "    sub_complex_max = set(clf.lower.maximum_simplices().simplices)\n",
    "    print(sub_complex_max)\n",
    "    # Step 5: Create the chromatic simplicial complex and set its simplex weights\n",
    "    simplicial_complex = chro.SimplicialComplex(complex_simplices)\n",
    "    simplicial_complex.set_simplex_weights(complex_simplices)\n",
    "\n",
    "    # Step 6: Set the sub-complex using the maximum simplices from clf.lower\n",
    "    sub_complex = chro.SimplicialComplex(sub_complex_max).simplices()  # compute the subsimplices\n",
    "    simplicial_complex.set_sub_complex(sub_complex)\n",
    "\n",
    "    # Step 7: Compute persistence for the simplicial complex\n",
    "    simplicial_complex.compute_persistence()\n",
    "\n",
    "    return simplicial_complex\n",
    "\n",
    "# Usage example\n",
    "# simplicial_complex = configure_chromatic_simplicial_complex(sample_cl4)\n",
    "def print_non_trivial_bars(simplicial_complex):\n",
    "    \"\"\"\n",
    "    Prints all non-trivial bars of a simplicial complex.\n",
    "\n",
    "    Parameters:\n",
    "    simplicial_complex: The simplicial complex object with GROUPS and bars method.\n",
    "    \"\"\"\n",
    "    print(\"Bars:\")\n",
    "    for grp in simplicial_complex.GROUPS:\n",
    "        print()\n",
    "        print(f\"  {grp}:\")\n",
    "        bars_all = simplicial_complex.bars(grp, return_as='dict')\n",
    "        for dim, bars in sorted(bars_all.items()):\n",
    "            print(f\"    dim {dim} ... \", end=\"\")\n",
    "            print(\", \".join(str(bar) for bar in sorted(bars)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLFiltration:rescaling filtration values to ordinal numbers.\n",
      "{(0, 1), (1, 3), (2,), (2, 3), (1,), (0, 2), (0,), (3,)}\n"
     ]
    }
   ],
   "source": [
    "from commutazzio.filtration import SimplexTree\n",
    "u=SimplexTree()\n",
    "for simplex in [(0,),(1,),(2,),(0,1),(0,2)]:\n",
    "    u.insert(simplex,0)\n",
    "u.insert((1,2),1)\n",
    "for simplex in [(3,),(1,3),(2,3)]:\n",
    "    u.insert(simplex,2)\n",
    "u.insert((1,2,3),3)\n",
    "u.insert((0,1,2),4)\n",
    "#---------------------------------------\n",
    "l=SimplexTree()\n",
    "for simplex in [(0,),(1,),(2,),(0,1),(0,2)]:\n",
    "    l.insert(simplex,0)\n",
    "for simplex in [(3,),(1,3),(2,3)]:\n",
    "    l.insert(simplex,2)\n",
    "manual_example = CLFiltration(upper=u, lower=l,ladder_length=5,h_params=[0,1,2,3,4])\n",
    "example=configure_chromatic_simplicial_complex(manual_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,), (1,), (2,), (3,), (0, 1), (0, 2), (1, 3), (2, 3)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_example.lower.maximum_simplicial_complex.simplices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a dictionary of simplices and filtration values.\n",
    "# All subsimplices of the given simplices will be added with filtration value 0.\n",
    "complex_simplices = {\n",
    "    (0,)    : 0, # would be still added with weight 0 if not explicitly stated\n",
    "    (1,)    : 0, # would be still added with weight 0 if not explicitly stated\n",
    "    (2,)    : 0, # would be still added with weight 0 if not explicitly stated\n",
    "    (0,1)   : 0, # would be still added with weight 0 if not explicitly stated\n",
    "    (0,2)   : 0, # would be still added with weight 0 if not explicitly stated\n",
    "    (1,2)   : 1,\n",
    "    (3,)    : 2,\n",
    "    (1,3)   : 2,\n",
    "    (2,3)   : 2,\n",
    "    (1,2,3) : 3,\n",
    "    (0,1,2) : 4\n",
    "}\n",
    "\n",
    "# Define subcomplex by the maximal simplices \n",
    "sub_complex_max = {(0,1), (0,2), (1,3), (2,3)}\n",
    "sub_complex = chro.SimplicialComplex(sub_complex_max).simplices() # compute the subsimplices\n",
    "\n",
    "simplicial_complex = chro.SimplicialComplex(complex_simplices)\n",
    "simplicial_complex.set_simplex_weights(complex_simplices)\n",
    "simplicial_complex.set_sub_complex(sub_complex)\n",
    "simplicial_complex.compute_persistence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bars:\n",
      "\n",
      "  kernel:\n",
      "    dim 1 ... (4, inf)\n",
      "\n",
      "  sub_complex:\n",
      "    dim 0 ... (0, inf)\n",
      "    dim 1 ... (2, inf)\n",
      "\n",
      "  image:\n",
      "    dim 0 ... (0, inf)\n",
      "    dim 1 ... (2, 4)\n",
      "\n",
      "  complex:\n",
      "    dim 0 ... (0, inf)\n",
      "    dim 1 ... (1, 4), (2, 3)\n",
      "\n",
      "  cokernel:\n",
      "    dim 1 ... (1, 3)\n",
      "\n",
      "  relative:\n",
      "    dim 1 ... (1, 3)\n",
      "    dim 2 ... (4, inf)\n"
     ]
    }
   ],
   "source": [
    "print_non_trivial_bars(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bars:\n",
      "\n",
      "  kernel:\n",
      "    dim 1 ... (4, inf)\n",
      "\n",
      "  sub_complex:\n",
      "    dim 0 ... (0, inf)\n",
      "    dim 1 ... (2, inf)\n",
      "\n",
      "  image:\n",
      "    dim 0 ... (0, inf)\n",
      "    dim 1 ... (2, 4)\n",
      "\n",
      "  complex:\n",
      "    dim 0 ... (0, inf)\n",
      "    dim 1 ... (1, 4), (2, 3)\n",
      "\n",
      "  cokernel:\n",
      "    dim 1 ... (1, 3)\n",
      "\n",
      "  relative:\n",
      "    dim 1 ... (1, 3)\n",
      "    dim 2 ... (4, inf)\n"
     ]
    }
   ],
   "source": [
    "print_non_trivial_bars(simplicial_complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def collect_data_from_db_files(dirnames, fn_pattern, db_2_df):\n",
    "    \"\"\"\n",
    "    Loop through all files in the directory of form \"{fn_pattern}_*.db\". For each file, \n",
    "    read the database by applying the provided function (db_2_df), which returns a DataFrame.\n",
    "    All DataFrames are then combined into one DataFrame.\n",
    "\n",
    "    Args:\n",
    "        dirname (str): The directory containing the db files.\n",
    "        fn_pattern (str): The filename pattern to match.\n",
    "        db_2_df (function): Function to convert db data into DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The combined data from all matched db files.\n",
    "    \"\"\"\n",
    "    all_data = pd.DataFrame()\n",
    "    for dirname in dirnames:\n",
    "        # Loop through all files in the directory matching the pattern\n",
    "        for filename in sorted(glob.glob(os.path.join(dirname, f\"{fn_pattern}*.db\"))):\n",
    "            print(f\"Processing file: {filename}\")\n",
    "            new_db = CLFiltrationDB(filename, create_new=False)\n",
    "            df_new = db_2_df(new_db)\n",
    "            all_data = pd.concat([all_data, df_new], ignore_index=True)\n",
    "            print(f\"Finished processing file: {filename}\")\n",
    "\n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirnames = ['./databases','./databases/new_topoblaze/']\n",
    "fn_pattern = 'pc_EC2_4'\n",
    "\n",
    "all_data_4 = collect_data_from_db_files(dirnames, fn_pattern, sqlite_to_df_cl4_pc)\n",
    "all_data_4.to_pickle('cl4_df_pc_large.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirname = './databases'\n",
    "dirnames = ['./databases','./databases/new_topoblaze/']\n",
    "fn_pattern = 'pc_EC2_n'\n",
    "\n",
    "all_data_n = collect_data_from_db_files(dirnames, fn_pattern, sqlite_to_df_cln_pc)\n",
    "all_data_n.to_pickle('cln_df_pc_large.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_data_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
